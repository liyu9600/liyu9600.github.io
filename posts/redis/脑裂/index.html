<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Redis-脑裂 | 日拱一卒</title>
<meta name="keywords" content="">
<meta name="description" content="定义 主从集群中，同时又两个主节点，它们都能接收写请求。
影响 客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端往不同的主节点写入数据。严重的话，会进一步导致数据丢失。
问题 在主从集群中，客户端发送的数据丢失。
分析 确认是否数据同步出现了问题
在主从集群中发生数据丢失，最常见的原因是主库的数据还没有同步到从库，结果主库发生故障，等从库升级为主库后，未同步的数据丢失。 可以通过对比主从库上复制进度差值来进行判断，如果slave_repl_offset&lt;master_repl_offset，那么就可以认定数据丢失是由数据同步未完成导致的。 排查客户端的操作日志，发生脑裂现象
发现在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。相当于主从集群中同时有了两个主库。 发现原主库假故障导致脑裂
采用哨兵机制进行主从切换，当主仓切换发生时，一定是有超过预设数量的（quorum配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线。然后，哨兵开始执行切换操作。哨兵切换完成后客户端会和新主库进行通信，发送请求操作。 切换过程中，客户端仍然和原主库通信。表明原主库并没有真的发生故障（主库进程挂掉） 原因： 原主库所在的机器CPU被其他程序临时用满，导致Redis主库暂时无法响应心跳，随后当CPU使用率降下来，原主库有可开始正常服务请求了。 主库自身遇到堵塞的情况。例如，处理bigKey或是发生内存swap，短时间内无法响应心跳，等主库堵塞解除后，主库又恢复正常。 脑裂会导致数据丢失
主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行slave of命令，和新主库重新进行全量同步。 在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的RDB文件。 原主库在主从切换期间保存的新写数据丢失。 解决方案 思路: 因为问题是出在原主库发生假故障后仍然能接收请求上，所以从主从集群机制的配置项中查找是否能限制主库接收请求的配置。
min-slaves-to-write：设置主库能进行数据同步的最少从库数量。 min-slaves-max-lag：设置主从库期间进行数据复制时，从库给主库发送ACK消息的最大延迟（以秒为单位）。 假设min-slaves-to-write=N &amp;&amp; min-slaves-max-lag=T，要求主库连接的从库至少有N个从库，和主库进行数据复制的ACK消息延迟不能超过T秒，否则主库就不会再接收客户端的请求了。 建议 假设从库有K个，配置min-slaves-to-write=K/2&#43;1 &amp;&amp; 10&lt;=min-slaves-max-lag&lt;=20。">
<meta name="author" content="">
<link rel="canonical" href="https://liyu9600.github.io/posts/redis/%E8%84%91%E8%A3%82/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css" integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://liyu9600.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://liyu9600.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://liyu9600.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://liyu9600.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://liyu9600.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Redis-脑裂" />
<meta property="og:description" content="定义 主从集群中，同时又两个主节点，它们都能接收写请求。
影响 客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端往不同的主节点写入数据。严重的话，会进一步导致数据丢失。
问题 在主从集群中，客户端发送的数据丢失。
分析 确认是否数据同步出现了问题
在主从集群中发生数据丢失，最常见的原因是主库的数据还没有同步到从库，结果主库发生故障，等从库升级为主库后，未同步的数据丢失。 可以通过对比主从库上复制进度差值来进行判断，如果slave_repl_offset&lt;master_repl_offset，那么就可以认定数据丢失是由数据同步未完成导致的。 排查客户端的操作日志，发生脑裂现象
发现在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。相当于主从集群中同时有了两个主库。 发现原主库假故障导致脑裂
采用哨兵机制进行主从切换，当主仓切换发生时，一定是有超过预设数量的（quorum配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线。然后，哨兵开始执行切换操作。哨兵切换完成后客户端会和新主库进行通信，发送请求操作。 切换过程中，客户端仍然和原主库通信。表明原主库并没有真的发生故障（主库进程挂掉） 原因： 原主库所在的机器CPU被其他程序临时用满，导致Redis主库暂时无法响应心跳，随后当CPU使用率降下来，原主库有可开始正常服务请求了。 主库自身遇到堵塞的情况。例如，处理bigKey或是发生内存swap，短时间内无法响应心跳，等主库堵塞解除后，主库又恢复正常。 脑裂会导致数据丢失
主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行slave of命令，和新主库重新进行全量同步。 在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的RDB文件。 原主库在主从切换期间保存的新写数据丢失。 解决方案 思路: 因为问题是出在原主库发生假故障后仍然能接收请求上，所以从主从集群机制的配置项中查找是否能限制主库接收请求的配置。
min-slaves-to-write：设置主库能进行数据同步的最少从库数量。 min-slaves-max-lag：设置主从库期间进行数据复制时，从库给主库发送ACK消息的最大延迟（以秒为单位）。 假设min-slaves-to-write=N &amp;&amp; min-slaves-max-lag=T，要求主库连接的从库至少有N个从库，和主库进行数据复制的ACK消息延迟不能超过T秒，否则主库就不会再接收客户端的请求了。 建议 假设从库有K个，配置min-slaves-to-write=K/2&#43;1 &amp;&amp; 10&lt;=min-slaves-max-lag&lt;=20。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://liyu9600.github.io/posts/redis/%E8%84%91%E8%A3%82/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-03T11:11:23&#43;08:00" />
<meta property="article:modified_time" content="2022-07-03T11:11:23&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Redis-脑裂"/>
<meta name="twitter:description" content="定义 主从集群中，同时又两个主节点，它们都能接收写请求。
影响 客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端往不同的主节点写入数据。严重的话，会进一步导致数据丢失。
问题 在主从集群中，客户端发送的数据丢失。
分析 确认是否数据同步出现了问题
在主从集群中发生数据丢失，最常见的原因是主库的数据还没有同步到从库，结果主库发生故障，等从库升级为主库后，未同步的数据丢失。 可以通过对比主从库上复制进度差值来进行判断，如果slave_repl_offset&lt;master_repl_offset，那么就可以认定数据丢失是由数据同步未完成导致的。 排查客户端的操作日志，发生脑裂现象
发现在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。相当于主从集群中同时有了两个主库。 发现原主库假故障导致脑裂
采用哨兵机制进行主从切换，当主仓切换发生时，一定是有超过预设数量的（quorum配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线。然后，哨兵开始执行切换操作。哨兵切换完成后客户端会和新主库进行通信，发送请求操作。 切换过程中，客户端仍然和原主库通信。表明原主库并没有真的发生故障（主库进程挂掉） 原因： 原主库所在的机器CPU被其他程序临时用满，导致Redis主库暂时无法响应心跳，随后当CPU使用率降下来，原主库有可开始正常服务请求了。 主库自身遇到堵塞的情况。例如，处理bigKey或是发生内存swap，短时间内无法响应心跳，等主库堵塞解除后，主库又恢复正常。 脑裂会导致数据丢失
主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行slave of命令，和新主库重新进行全量同步。 在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的RDB文件。 原主库在主从切换期间保存的新写数据丢失。 解决方案 思路: 因为问题是出在原主库发生假故障后仍然能接收请求上，所以从主从集群机制的配置项中查找是否能限制主库接收请求的配置。
min-slaves-to-write：设置主库能进行数据同步的最少从库数量。 min-slaves-max-lag：设置主从库期间进行数据复制时，从库给主库发送ACK消息的最大延迟（以秒为单位）。 假设min-slaves-to-write=N &amp;&amp; min-slaves-max-lag=T，要求主库连接的从库至少有N个从库，和主库进行数据复制的ACK消息延迟不能超过T秒，否则主库就不会再接收客户端的请求了。 建议 假设从库有K个，配置min-slaves-to-write=K/2&#43;1 &amp;&amp; 10&lt;=min-slaves-max-lag&lt;=20。"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://liyu9600.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Redis-脑裂",
      "item": "https://liyu9600.github.io/posts/redis/%E8%84%91%E8%A3%82/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Redis-脑裂",
  "name": "Redis-脑裂",
  "description": "定义 主从集群中，同时又两个主节点，它们都能接收写请求。\n影响 客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端往不同的主节点写入数据。严重的话，会进一步导致数据丢失。\n问题 在主从集群中，客户端发送的数据丢失。\n分析 确认是否数据同步出现了问题\n在主从集群中发生数据丢失，最常见的原因是主库的数据还没有同步到从库，结果主库发生故障，等从库升级为主库后，未同步的数据丢失。 可以通过对比主从库上复制进度差值来进行判断，如果slave_repl_offset\u0026lt;master_repl_offset，那么就可以认定数据丢失是由数据同步未完成导致的。 排查客户端的操作日志，发生脑裂现象\n发现在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。相当于主从集群中同时有了两个主库。 发现原主库假故障导致脑裂\n采用哨兵机制进行主从切换，当主仓切换发生时，一定是有超过预设数量的（quorum配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线。然后，哨兵开始执行切换操作。哨兵切换完成后客户端会和新主库进行通信，发送请求操作。 切换过程中，客户端仍然和原主库通信。表明原主库并没有真的发生故障（主库进程挂掉） 原因： 原主库所在的机器CPU被其他程序临时用满，导致Redis主库暂时无法响应心跳，随后当CPU使用率降下来，原主库有可开始正常服务请求了。 主库自身遇到堵塞的情况。例如，处理bigKey或是发生内存swap，短时间内无法响应心跳，等主库堵塞解除后，主库又恢复正常。 脑裂会导致数据丢失\n主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行slave of命令，和新主库重新进行全量同步。 在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的RDB文件。 原主库在主从切换期间保存的新写数据丢失。 解决方案 思路: 因为问题是出在原主库发生假故障后仍然能接收请求上，所以从主从集群机制的配置项中查找是否能限制主库接收请求的配置。\nmin-slaves-to-write：设置主库能进行数据同步的最少从库数量。 min-slaves-max-lag：设置主从库期间进行数据复制时，从库给主库发送ACK消息的最大延迟（以秒为单位）。 假设min-slaves-to-write=N \u0026amp;\u0026amp; min-slaves-max-lag=T，要求主库连接的从库至少有N个从库，和主库进行数据复制的ACK消息延迟不能超过T秒，否则主库就不会再接收客户端的请求了。 建议 假设从库有K个，配置min-slaves-to-write=K/2+1 \u0026amp;\u0026amp; 10\u0026lt;=min-slaves-max-lag\u0026lt;=20。",
  "keywords": [
    
  ],
  "articleBody": "定义 主从集群中，同时又两个主节点，它们都能接收写请求。\n影响 客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端往不同的主节点写入数据。严重的话，会进一步导致数据丢失。\n问题 在主从集群中，客户端发送的数据丢失。\n分析 确认是否数据同步出现了问题\n在主从集群中发生数据丢失，最常见的原因是主库的数据还没有同步到从库，结果主库发生故障，等从库升级为主库后，未同步的数据丢失。 可以通过对比主从库上复制进度差值来进行判断，如果slave_repl_offset",
  "wordCount" : "35",
  "inLanguage": "en",
  "datePublished": "2022-07-03T11:11:23+08:00",
  "dateModified": "2022-07-03T11:11:23+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://liyu9600.github.io/posts/redis/%E8%84%91%E8%A3%82/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "日拱一卒",
    "logo": {
      "@type": "ImageObject",
      "url": "https://liyu9600.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://liyu9600.github.io" accesskey="h" title="日拱一卒 (Alt + H)">日拱一卒</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Redis-脑裂
    </h1>
    <div class="post-meta"><span title='2022-07-03 11:11:23 +0800 CST'>July 3, 2022</span>

</div>
  </header> 
  <div class="post-content"><h3 id="定义">定义<a hidden class="anchor" aria-hidden="true" href="#定义">#</a></h3>
<p>主从集群中，同时又两个主节点，它们都能接收写请求。</p>
<h3 id="影响">影响<a hidden class="anchor" aria-hidden="true" href="#影响">#</a></h3>
<p>客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端往不同的主节点写入数据。严重的话，会进一步导致数据丢失。</p>
<h3 id="问题">问题<a hidden class="anchor" aria-hidden="true" href="#问题">#</a></h3>
<p>在主从集群中，客户端发送的数据丢失。</p>
<h4 id="分析">分析<a hidden class="anchor" aria-hidden="true" href="#分析">#</a></h4>
<ol>
<li>
<p>确认是否数据同步出现了问题</p>
<ol>
<li>在主从集群中发生数据丢失，最常见的原因是<strong>主库的数据还没有同步到从库，结果主库发生故障，等从库升级为主库后，未同步的数据丢失。</strong></li>
<li>可以通过对比主从库上复制进度差值来进行判断，如果<code>slave_repl_offset&lt;master_repl_offset</code>，那么就可以认定数据丢失是由数据同步未完成导致的。</li>
</ol>
</li>
<li>
<p>排查客户端的操作日志，发生脑裂现象</p>
<ol>
<li>发现在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。相当于主从集群中同时有了两个主库。</li>
</ol>
</li>
<li>
<p>发现原主库假故障导致脑裂</p>
<ol>
<li>采用哨兵机制进行主从切换，当主仓切换发生时，一定是有超过预设数量的（quorum配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线。然后，哨兵开始执行切换操作。哨兵切换完成后客户端会和新主库进行通信，发送请求操作。</li>
<li>切换过程中，客户端仍然和原主库通信。表明<strong>原主库并没有真的发生故障</strong>（主库进程挂掉）</li>
<li>原因：
<ul>
<li>原主库所在的机器CPU被其他程序临时用满，导致Redis主库暂时无法响应心跳，随后当CPU使用率降下来，原主库有可开始正常服务请求了。</li>
<li>主库自身遇到堵塞的情况。例如，处理bigKey或是发生内存swap，短时间内无法响应心跳，等主库堵塞解除后，主库又恢复正常。</li>
</ul>
</li>
</ol>
</li>
<li>
<p>脑裂会导致数据丢失</p>
<ol>
<li>主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行<code>slave of</code>命令，和新主库重新进行全量同步。</li>
<li>在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的RDB文件。</li>
<li>原主库在主从切换期间保存的新写数据丢失。</li>
</ol>
</li>
</ol>
<h3 id="解决方案">解决方案<a hidden class="anchor" aria-hidden="true" href="#解决方案">#</a></h3>
<p><strong>思路: 因为问题是出在原主库发生假故障后仍然能接收请求上，所以从主从集群机制的配置项中查找是否能限制主库接收请求的配置。</strong></p>
<ol>
<li><code>min-slaves-to-write</code>：设置主库能进行数据同步的最少从库数量。</li>
<li><code>min-slaves-max-lag</code>：设置主从库期间进行数据复制时，从库给主库发送ACK消息的最大延迟（以秒为单位）。</li>
<li>假设<code>min-slaves-to-write=N &amp;&amp; min-slaves-max-lag=T</code>，要求主库连接的从库至少有N个从库，和主库进行数据复制的ACK消息延迟不能超过T秒，否则主库就不会再接收客户端的请求了。</li>
</ol>
<h3 id="建议">建议<a hidden class="anchor" aria-hidden="true" href="#建议">#</a></h3>
<p>假设从库有K个，配置<code>min-slaves-to-write=K/2+1 &amp;&amp; 10&lt;=min-slaves-max-lag&lt;=20</code>。</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://liyu9600.github.io">日拱一卒</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
